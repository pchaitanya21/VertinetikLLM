{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a Gemini instance using VertexAI and generate the graph code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the Runtime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Using Google Colab Run this step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "LOCATION = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and model calling and sending message functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_gemini(prompt, generation_config=GenerationConfig(temperature=1.0)):\n",
    "    wait_time = 1\n",
    "    while True:\n",
    "        try:\n",
    "            response = model.generate_content(prompt, generation_config=generation_config).text\n",
    "            return response\n",
    "            break  # Exit the loop if successful\n",
    "        except Exception as e:  # Replace with the actual exception type\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  # Double the wait time\n",
    "\n",
    "def send_message_gemini(model, prompt):    \n",
    "    wait_time = 1\n",
    "    while True:\n",
    "        try:\n",
    "            response = model.send_message(prompt).text\n",
    "            return response\n",
    "            break  # Exit the loop if successful\n",
    "        except Exception as e:  # Replace with the actual exception type\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  # Double the wait time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the LLM system prompt and the prompt to pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "model_gis = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=[\n",
    "        \"Your role: A professional Geo-information scientist and programmer good at Python.\", \n",
    "        \" You have worked on Geographic information science more than 20 years, and know every detail and pitfall when processing spatial data and coding.\",\n",
    "        \"Your programs are always concise and robust, considering the various data circumstances, such as map projections, column data types, and spatial joinings.\",\n",
    "        \"You are also very experienced on generating maps\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "chat = model_gis.start_chat()\n",
    "\n",
    "prompt = r\"\"\"Your task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:\n",
    " 1) Find out Census tracts that contain hazardous waste facilities, then comppute and print out the population living in those tracts. The study area is North Carolina (NC), US.\n",
    "2) Generate a population choropleth map for all tract polygons in NC, rendering the color by tract population; and then highlight the borders of tracts that have hazardous waste facilities. Please draw all polygons, not only the highlighted ones. The map size is 15*10 inches.\n",
    "\n",
    "Your reply needs to meet these requirements:\n",
    " 1. Think step by step.\n",
    "2. Steps and data (both input and output) form a graph stored in NetworkX. Disconnected components are NOT allowed.\n",
    "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
    "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
    "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
    "6. You need to carefully name the output data node, making they human readable but not to long.\n",
    "7. The data and operation form a graph.\n",
    "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
    "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”: “D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
    "10. The connection between a node and an operation node is an edge.\n",
    "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
    "12. DO NOT generate code to implement the steps.\n",
    "13. Join the attribute to the vector layer via a common attribute if necessary.\n",
    "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
    "15. Note that GraphML writer does not support class dict or list as data values.\n",
    "16. You need spatial data (e.g., vector or raster) to make a map.\n",
    "17. Do not put the GraphML writing process as a step in the graph.\n",
    "18. Keep the graph concise, DO NOT use too many operation nodes.\n",
    "19. Save the network into GraphML format, save it at: C:\\Users\\chait\\Projects\\LLM-Geo\\Resident_at_risk_counting\\Resident_at_risk_counting.graphml\n",
    "\n",
    "Your reply example:\n",
    "```python\n",
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "# Add nodes and edges for the graph\n",
    "# 1 Load hazardous waste site shapefile\n",
    "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
    "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
    "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
    "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
    "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
    "...\n",
    "``` \"\"\"\n",
    "\n",
    "response = send_message_gemini(chat, prompt)\n",
    "\n",
    "# Save the response to a file\n",
    "output_file_path = \"C:/Users/chait/Projects/VertinetikLLM/generated_files/graph_response_LLM.py\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Write the response to the file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(response)\n",
    "\n",
    "# Optional: Print the response to the console for verification\n",
    "print(\"Response from LLM:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
